create DATABASE testdb;
use testdb;
create table orders_data
(
 cust_id int,
 order_id int,
 country varchar(50),
 state varchar(50)
);
insert into orders_data values
(1,100,'USA','Seattle'),
(2,101,'INDIA','UP'),
(2,103,'INDIA','Bihar'),
(4,108,'USA','WDC'),
(5,109,'UK','London'),
(4,110,'USA','WDC'),
(3,120,'INDIA','AP'),
(2,121,'INDIA','Goa'),
(1,131,'USA','Seattle'),
(6,142,'USA','Seattle'),
(7,150,'USA','Seattle');

select * from orders_data;

-- using the having clause 
-- Write a query to find the country where only 1 order was placed
select country from  orders_data group by country HAVING count(*)=1;

-- using the group concate 
-- Query - Write a query to print distinct states present in the dataset for each country?
select country ,GROUP_CONCAT(state SEPARATOR'<>') AS states_ditalis from orders_data group by country ;

create table employees
(
    id int,
    name varchar(50),
    salary int
);
insert into employees values(1,'Shashank',5000),(2,'Amit',5500),(3,'Rahul',7000),(4,'Rohit',6000),(5,'Nitin',4000),(6,'Sunny',7500);
select * from employees;
--Write a query to print all those employee records who are getting more salary than 'Rohit'
select * from employees where salary > (select salary from employees where name='Rohit');

--Write a query to print all orders which were placed in 'Seattle' or 'Goa'
select * from orders_data where state in ('Seattle','Goa');

create table customer_order_data
(
    order_id int,
    cust_id int,
    supplier_id int,
    cust_country varchar(50)
);

Create table student_marks
(
    stu_id int,
    stu_name varchar(50),
    total_marks int
);

insert into student_marks values
(1,'Shashank',50),
(2,'Rahul',91),
(3,'Amit',74),
(4,'Nikhil',65),
(5,'Rohit',86),
(6,'Deepak',77);

select * from student_marks;

/*Write a query to caluclate the grades for a student by following below criteria
 marks >= 90 , grade A+
marks < 90 and marks >=85, grade A
 marks < 85 and marks >=75, grade B+
 marks < 75 and marks >=60, grade B
 marks < 60 , grade C */

 select *,
        CASE
            when total_marks>=90 then 'A+'
            when total_marks>=85 and total_marks<90 then 'A'
            when total_marks>=75 and total_marks<85 then 'B+'
            when total_marks>=60 and total_marks<75 then 'B'
            else 'C'
        end as grade_marks
from student_marks;

insert into customer_order_data values(101,200,300,'USA'),(102,201,301,'INDIA'),(103,202,302,'USA'),(104,203,303,'UK');

select * from customer_order_data;
create table supplier_data
(
    supplier_id int,
    sup_country varchar(50)
);
insert into supplier_data values(300,'USA'),(303,'UK');

/*write a query to find all customer order data where all coustomers are from same countries 
 as the suppliers*/
select * from customer_order_data where cust_country in (select distinct(sup_country ) from supplier_data );

-- Uber SQL Interview questions
create table tree
(
    node int,
    parent int
);

insert into tree values (5,8),(9,8),(4,5),(2,9),(1,5),(3,9),(8,null);

select * from tree;
select * ,
       CASE
           when node not in (select distinct(parent) from tree where parent is not null ) then 'leaf'
           when parent is null then 'Root'
           else 'Inner'
        end as types_node
from tree; 

select node,
       CASE
            when node not in (select distinct parent from tree where parent is not null) then 'LEAF'
            when parent is null then 'ROOT'
            else 'INNER'
       END as node_type
from tree;
create table transactions
(
    trx_date date,
    merchant_id varchar(10),
    amount int,
    payment_mode varchar(10)
);

insert into transactions values
('2022-04-02','m1',150,'CASH'),
('2022-04-02','m1',500,'ONLINE'),
('2022-04-03','m2',450,'ONLINE'),
('2022-04-03','m1',100,'CASH'),('2022-04-03','m3',600,'CASH'),
('2022-04-05','m5',200,'ONLINE'),
('2022-04-05','m2',100,'ONLINE');

select * from transactions;

-- writer a query to find the total amount paid by cash and online for EACH marchant id 
select merchant_id,
      sum(case when payment_mode='ONLINE' then amount else 0 end ) as total_online_pay,
      sum(case when payment_mode='CASH' then amount else 0 end ) as total_cash_pay
from transactions GROUP BY merchant_id;

select merchant_id,
       sum(case when payment_mode = 'CASH' then amount else 0 end) as cash_amount,
       sum(case when payment_mode = 'ONLINE' then amount else 0 end) as online_amount
from transactions 
group by merchant_id;

# Examples for join
create table orders
(
    order_id int,
    cust_id int,
    order_dat date, 
    shipper_id int
);

create table customers
(
    cust_id int,
    cust_name varchar(50),
    country varchar(50)
);

create table shippers
(
    ship_id int,
    shipper_name varchar(50)
);

insert into orders values(10308, 2, '2022-09-15', 3);
insert into orders values(10309, 30, '2022-09-16', 1);
insert into orders values(10310, 41, '2022-09-19', 2);

insert into customers values(1, 'Neel', 'India');
insert into customers values(2, 'Nitin', 'USA');
insert into customers values(3, 'Mukesh', 'UK');

insert into shippers values(3,'abc');
insert into shippers values(1,'xyz');

select * from orders;
select * from customers;
select * from shippers;

-- inner JOIN
--get the customer informations for each order order, if value of customer is present in orders TABLE
select cs.*,o.*

from customers cs 
inner join orders o on cs.cust_id=o.cust_id;

select o.*, c.*
from orders o
inner join customers c on o.cust_id = c.cust_id;



# How to join more than 2 datasets?
# perform inner JOIN
# get the customer informations for each order order, if value of customer is present in orders TABLE
# also get the information of shipper name

select o.*, c.*,s.shipper_name
from orders o
inner join customers c on o.cust_id = c.cust_id
inner join shippers s on o.shipper_id=s.ship_id;

select 
o.*, c.*, s.*
from orders o
inner join customers c on o.cust_id = c.cust_id
inner join shippers s on o.shipper_id = s.ship_id;

create table employees_full_data
(
    emp_id int,
    name varchar(50),
    mgr_id int
);

insert into employees_full_data values(1, 'Shashank', 3);
insert into employees_full_data values(2, 'Amit', 3);
insert into employees_full_data values(3, 'Rajesh', 4);
insert into employees_full_data values(4, 'Ankit', 6);
insert into employees_full_data values(6, 'Nikhil', null);

select * from employees_full_data;

# Write a query to print the distinct names of managers??
select emp1.*,emp.*

from employees_full_data emp
right join employees_full_data emp1 on emp.emp_id=emp1.mgr_id;

---------------------END--------------------------------------------

create database test;

use test;

create table customers
(
    id int,
    name varchar(50)
);

create table orders
(
    order_id int,
    amount int,
    cust_id int
);

insert into customers values(1,'John');

insert into customers values(2,'David');

insert into customers values(3,'Ronn');

insert into customers values(4,'Betty');


insert into orders values(1,100,10);

insert into orders values(2,500,3);

insert into orders values(3,300,6);

insert into orders values(4,800,2);

insert into orders values(5,350,1);

select * from customers;

select * from orders;

# Get the orders information along with customers full details
# if order amount were greater than 400
SELECT
o.*,c.*
from orders o 
inner join customers c on o.cust_id=c.id and o.amount>400;

# Window Functions
create table shop_sales_data
(
sales_date date,
shop_id varchar(5),
sales_amount int
);

insert into shop_sales_data values('2022-02-14','S1',200);
insert into shop_sales_data values('2022-02-15','S1',300);
insert into shop_sales_data values('2022-02-14','S2',600);
insert into shop_sales_data values('2022-02-15','S3',500);
insert into shop_sales_data values('2022-02-18','S1',400);
insert into shop_sales_data values('2022-02-17','S2',250);
insert into shop_sales_data values('2022-02-20','S3',300);


select * from shop_sales_data;

# Total count of sales for each shop 

select shop_id , count(*) from shop_sales_data group by shop_id;

--another way 
select * ,sum(sales_amount) over (partition by shop_id) from shop_sales_data;
create table amazon_sales_data
(
    sales_data date,
    sales_amount int
);

insert into amazon_sales_data values('2022-08-21',500);
insert into amazon_sales_data values('2022-08-22',600);
insert into amazon_sales_data values('2022-08-19',300);

insert into amazon_sales_data values('2022-08-18',200);

insert into amazon_sales_data values('2022-08-25',800);

select * from amazon_sales_data;

-- Query - Calculate the date wise rolling average of amazon sales
select *, avg(sales_amount) over(order by sales_data ) as rolling_avg from amazon_sales_data;
# Rank(), Row_Number(), Dense_Rank() window functions

insert into shop_sales_data values('2022-02-19','S1',400);
insert into shop_sales_data values('2022-02-20','S1',400);
insert into shop_sales_data values('2022-02-22','S1',300);
insert into shop_sales_data values('2022-02-25','S1',200);
insert into shop_sales_data values('2022-02-15','S2',600);
insert into shop_sales_data values('2022-02-16','S2',600);
insert into shop_sales_data values('2022-02-16','S3',500);
insert into shop_sales_data values('2022-02-18','S3',500);
insert into shop_sales_data values('2022-02-19','S3',300);

select * from shop_sales_data;
select *,
       row_number() over(partition by shop_id order by sales_amount desc) as row_num,
       rank() over(partition by shop_id order by sales_amount desc) as rank_val,
       dense_rank() over(partition by shop_id order by sales_amount desc) as dense_rank_val
from shop_sales_data;

create table employees
(
    emp_id int,
    salary int,
    dept_name VARCHAR(30)

);

insert into employees values(1,10000,'Software');
insert into employees values(2,11000,'Software');
insert into employees values(3,11000,'Software');
insert into employees values(4,11000,'Software');
insert into employees values(5,15000,'Finance');
insert into employees values(6,15000,'Finance');
insert into employees values(7,15000,'IT');
insert into employees values(8,12000,'HR');
insert into employees values(9,12000,'HR');
insert into employees values(10,11000,'HR');

select * from employees;

# Query - get one employee from each department who is getting maximum salary (employee can be random if salary is same)
select tmp.* from (select *,ROW_NUMBER()over(PARTITION BY dept_name order by salary DESC) as max_sal  from employees) tmp where max_sal=1 ;

# Example for lag and lead
create table daily_sales
(
sales_date date,
sales_amount int
);


insert into daily_sales values('2022-03-11',400);
insert into daily_sales values('2022-03-12',500);
insert into daily_sales values('2022-03-13',300);
insert into daily_sales values('2022-03-14',600);
insert into daily_sales values('2022-03-15',500);
insert into daily_sales values('2022-03-16',200);

select * from daily_sales;
 select * ,
        lag(sales_amount,1,0)over(order by sales_date)as previous_val,
        sales_amount-lag(sales_amount,1,0)over(order by sales_date) as different_val
  from daily_sales;

  select *,
         sum(sales_amount)over(order by sales_date rows between 2 preceding and 1 following) as sum_of_4days from daily_sales;
-- exclude current ROW
 select *,
        sum(sales_amount)over(order by sales_date rows between 1 preceding and 1 following )-sales_amount as total_sum_exclude_currents 
from daily_sales;

--- range between 

select *,
       sum(sales_amount)over(order by sales_amount range between 200 preceding and 200 following) as total_sum
from daily_sales;

insert into daily_sales values('2022-03-20',900);
insert into daily_sales values('2022-03-23',200);
insert into daily_sales values('2022-03-25',300);
insert into daily_sales values('2022-03-29',250);

select * from daily_sales;

# Calculate the running sum for a week


select * ,
       sum(sales_amount)over(order by sales_date range between interval '6' day preceding and current row ) as weekly_amount
from daily_sales;

# Calculate the running sum for a month
select *,
        sum(sales_amount)over(order by sales_date range between interval 29 day preceding and current row) as monthly_amount
from daily_sales;

------------------------------------------------------------------------------------------------------------------
